{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JLU1xyzwk9l"
      },
      "source": [
        "Chloe Fugle (chloe.m.fugle.23@dartmouth.edu), 6/7/22, CS72 Final Project \n",
        "\n",
        "A searchable database of the Dartmouth College courses and their descriptions to allow students to more easily find classes related to their interests. The search uses a TF-IDF and WordNet algorithm to return the most relevant courses.  \n",
        "\n",
        "### Instructions:  \n",
        "To run the program, select Runtime -> Run all. Please note that due to the structure of the Dartmouth Timetable website, the program will take about 15 minutes to compile a searchable database.   \n",
        "To avoid this wait time, a file \"course_desc.txt\" has been included with the submission. This file contains the scraped and processed text. Upload the file to the Google Colab runtime using the file icon to the left and run every cell except for the cell titled \"Full web-scraper.\"  \n",
        "Once the pre-processing functions have been run, the search function (the last cell) can be run as many times as desired to search for courses. Courses are listed in order of relevance to the user's search.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "to-YXEVJumMr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dff63e5-621a-4fba-c585-08ced419ffe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# import necessary packages\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import fileinput\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from IPython.display import display\n",
        "from sklearn.metrics import pairwise_distances\n",
        "import numpy as np\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('wordnet')\n",
        "\n",
        "cell_executed = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ImkDwqE6xJ4h"
      },
      "outputs": [],
      "source": [
        "# Fetches the HTML text of the information contained within the table of courses\n",
        "# on the Dartmouth Timetable, found at https://oracle-www.dartmouth.edu/dart/groucho/timetable.display_courses\n",
        "#\n",
        "# input: none\n",
        "# output: BeautifulSoup HTML object containing HTML text of all courses offered,\n",
        "#     note: this includes the URL to the course description, but not the \n",
        "#           description itself\n",
        "\n",
        "def get_data():\n",
        "    trm = '202209' #22F\n",
        "    url = \"https://oracle-www.dartmouth.edu/dart/groucho/timetable.display_courses\"\n",
        "    payload = {\n",
        "        'classyear' : '2008',\n",
        "        'searchtype' : 'Subject Area(s)',\n",
        "        'pmode' : 'public',\n",
        "        'term' : '',\n",
        "        'levl' : '',\n",
        "        'fys' : 'n',\n",
        "        'wrt' : 'n',\n",
        "        'pe' : 'n',\n",
        "        'review' : 'n',\n",
        "        'crnl' : 'no_value',\n",
        "        'termradio' : 'allterms',\n",
        "        'terms' : '202209',\n",
        "        'hoursradio' : 'allhours',\n",
        "        'periods' : 'no_value',\n",
        "        'subjectradio' : 'allsubjects',\n",
        "        'depts' : 'no_value',\n",
        "        'deliveryradio' : 'alldelivery',\n",
        "        'deliverymodes' : 'no_value',\n",
        "        'distribs_i' : 'no_value',\n",
        "        'distribs_wc' : 'no_value',\n",
        "        'distribradio' : 'alldistribs',\n",
        "        'distribs' : 'no_value',\n",
        "        'sortorder' : 'dept'\n",
        "    }\n",
        "\n",
        "    rdata = requests.post(url, data = payload) #sends search criteria to Timetable, recieves HTML\n",
        "    soup = BeautifulSoup(rdata.text, features=\"lxml\") #initializes LXML from above as soup object for searching\n",
        "\n",
        "    datatable = soup.find('div', class_= 'data-table')\n",
        "    \n",
        "    return datatable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IkdpeHrR3VF5"
      },
      "outputs": [],
      "source": [
        "# Extracts course names and descriptions from the HTML text, creates a file\n",
        "# containing one course name (whitespace) and course description on each line.\n",
        "# Follows the link provided for each course to scrape the course description.\n",
        "#   note: due to the structure of the Dartmouth Timetable, this function \n",
        "#         takes about 14 min to run\n",
        "#\n",
        "# input: BeautifulSoup HTML object containing the text of all courses offered\n",
        "# output: file (\"class-desc.txt\") and dictionary containing the course and course descriptions\n",
        "\n",
        "def make_list_file(datatable):\n",
        "\n",
        "    timetable = open(\"timetable.txt\", \"w+\")\n",
        "    timetable.write(datatable.text)\n",
        "    timetable.close()\n",
        "    \n",
        "    # group information about each course together in a dictionary\n",
        "    i = 0   # file line number\n",
        "    j = -1  # current class line number\n",
        "    match = re.compile(r'202209').search\n",
        "    class_dict = {}\n",
        "    name_num_dict = {}\n",
        "    temp_list = []\n",
        "    class_name = \"\"\n",
        "    timetable = open(\"timetable.txt\", \"r\")\n",
        "\n",
        "    for line in timetable:\n",
        "      line = re.sub(r'[^a-zA-Z0-9_ ]', '', line) # remove all non-alphanumberic characters\n",
        "      if i<25:  # ignore first 25 lines of file\n",
        "        i += 1\n",
        "        continue\n",
        "      else:\n",
        "        if j == -1 and match(line): # course is held in specified term\n",
        "          j += 1\n",
        "          continue\n",
        "        if j >= 0 and j < 30:  # line contains information about relevant course\n",
        "          if j != 14:   # course name found on line 14 of class information\n",
        "            if len(line.strip()) != 0:\n",
        "              temp_list.append(line)\n",
        "            if j == 1:    # department 4-letter code\n",
        "              dept_code = line\n",
        "            if j == 2:    # course number\n",
        "              course_num = line\n",
        "            j += 1\n",
        "          else:\n",
        "            class_name = line\n",
        "            j += 1\n",
        "          if j == 29:   # each class contains 29 lines of information\n",
        "            class_dict[class_name] = temp_list\n",
        "            name_num_dict[class_name] = str(dept_code) + \" \" + str(course_num)\n",
        "            j = -1    # end of class information, reset count\n",
        "      i += 1\n",
        "\n",
        "    timetable.close()\n",
        "\n",
        "    # for every class in class dictionary, get the link to the course information\n",
        "    classdesc_dict = {}\n",
        "    link_list = datatable.find_all('a')   # get all <a> tags within the datatable\n",
        "\n",
        "    for classname in class_dict:  # for every class, get link\n",
        "      regex = re.compile(r'>'+re.escape(classname)+r'<')\n",
        "      for i in link_list:\n",
        "        if re.search(regex, str(i)):\n",
        "          new = re.sub(r'&amp;', r'&', str(i))  # fix link\n",
        "          newlink = BeautifulSoup(new)   # initialize text to search for link\n",
        "          justlink = newlink.find('a')['href'].split(\"'\")[1]  # get just the link\n",
        "          \n",
        "          # get course description text from link\n",
        "          rdata = requests.post(justlink)\n",
        "          soup = BeautifulSoup(rdata.text, features=\"lxml\")\n",
        "          text = str(soup.find_all('p'))\n",
        "\n",
        "          # make the stripped text pretty\n",
        "          if len(text.split(\"<p>\")) > 3:\n",
        "            temp = text.split(\"<p>\")[3]\n",
        "            if len(temp.split(\"</p>\")) > 0:\n",
        "              temp = temp.split(\"</p>\")[0]\n",
        "            else:\n",
        "              temp = \"No course description availible\"\n",
        "          else:\n",
        "            temp = \"No course description availible\"\n",
        "\n",
        "          # add to the course description dictionary\n",
        "          classdesc_dict[classname] = temp\n",
        "\n",
        "    # create file with course names and descriptions\n",
        "    course_desc = open(\"course_desc.txt\", \"w+\")\n",
        "    for course in classdesc_dict:\n",
        "      course_desc.write(course + \"\\t\" + classdesc_dict[course] + \"\\n\")\n",
        "\n",
        "    # create file containing class names and numbers\n",
        "    course_nums = open(\"course_nums.txt\", \"w+\")\n",
        "    for course in name_num_dict:\n",
        "      course_nums.write(course + \"\\t\" + name_num_dict[course] + \"\\n\")\n",
        "  \n",
        "    return classdesc_dict\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "          \n",
        "          \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "V-artoQYlDf7"
      },
      "outputs": [],
      "source": [
        "# Creates course description dictionary from file generated by make_list_file().\n",
        "# It is not necessary to run this function if you've run make_list_file(). This\n",
        "# function saves time if you already have the course description file.\n",
        "#\n",
        "# input: \"course_desc.txt\" generated by make_list_file(), contains one course \n",
        "#         name (whitespace) and course description on each line\n",
        "# output: dictionary containing each course name as a key and its description\n",
        "#         as the value\n",
        "\n",
        "def get_dict_from_file(filename):\n",
        "  filename = open(filename, \"r\")\n",
        "  classdesc_dict = {}\n",
        "\n",
        "  for line in filename:\n",
        "    name = line.split(\"\\t\")[0]\n",
        "    if len(line.split(\"\\t\")) > 1:\n",
        "      desc = line.split(\"\\t\")[1]\n",
        "    else:\n",
        "      desc = \"No course description avalible\"\n",
        "    classdesc_dict[name] = desc\n",
        "\n",
        "  return classdesc_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZctZkK_P1pam"
      },
      "outputs": [],
      "source": [
        "# Vectorizes every course description using TF-IDF. Generates a dictionary\n",
        "# of the course names and their sparce matrix of keywords.\n",
        "# TF-IDF code modified from code found at https://towardsdatascience.com/using-tf-idf-to-form-descriptive-chapter-summaries-via-keyword-extraction-4e6fd857d190\n",
        "#\n",
        "# inputs: \n",
        "#   classdesc_dict: dictionary of course names and their descriptions\n",
        "#   keywords: defaults to False, set to True for a printed list of courses and the\n",
        "#       keywords included in their descriptions and a list of all the keywords in\n",
        "#       alphabetical order\n",
        "# outputs:\n",
        "#   keynums_dict: dictionary of the course names and their sparce vectors\n",
        "#   colnames: list of the keywords associated with each number in the sparce vector\n",
        "\n",
        "\n",
        "def create_tfidf(classdesc_dict, keywords=False):\n",
        "\n",
        "  # download a set of stopwords\n",
        "  st = set(stopwords.words('english'))\n",
        "\n",
        "  # turn dictionary into list for use in tfidf\n",
        "  classlist = []\n",
        "  namelist = []   # list to keep the classes in to match with the keywords\n",
        "  for course in classdesc_dict:\n",
        "    classlist.append(course + \" \" + classdesc_dict[course])\n",
        "    namelist.append(course)\n",
        "\n",
        "  # extract keywords from each course description using tfidf vectorizer\n",
        "  vectorizer = TfidfVectorizer()\n",
        "  vectors = vectorizer.fit_transform(classlist)\n",
        "  names = vectorizer.get_feature_names()\n",
        "  data = vectors.todense().tolist()\n",
        "  df = pd.DataFrame(data, columns=names)\n",
        "  df = df[filter(lambda x: x not in list(st) , df.columns)]\n",
        "  df = df[filter(lambda x: x.isalpha() , df.columns)]\n",
        "\n",
        "\n",
        "  colnames = df.columns\n",
        "  keynums_dict = {}\n",
        "  keywords_dict = {}\n",
        "  j = 0\n",
        "  for index, row in df.iterrows():\n",
        "    temp_list = []\n",
        "    temp_words = []\n",
        "    for i in range(0, len(row)):\n",
        "      item = row[i]\n",
        "      temp_list.append(item)\n",
        "      if keywords and item != 0:\n",
        "        temp_words.append(colnames[i])\n",
        "    keynums_dict[namelist[j]] = temp_list\n",
        "    keywords_dict[namelist[j]] = temp_words\n",
        "    j += 1\n",
        "\n",
        "  # print dictionary of courses and their keywords in a pretty way\n",
        "  if keywords:\n",
        "    print(\"\")\n",
        "    for course in keywords_dict:\n",
        "      j = 0\n",
        "      print(course + \":\")\n",
        "      for word in keywords_dict[course]:\n",
        "          print(word, end = \" \")\n",
        "          j += 1\n",
        "          if j > 20:\n",
        "            print(\"\")\n",
        "            j = 0\n",
        "      print(\"\\n\")\n",
        "\n",
        "    # print list of keywords in a pretty way\n",
        "    print(\"\")\n",
        "    j = 0\n",
        "    for word in matrix_names:\n",
        "      print(word, end=\" \")\n",
        "      j += 1\n",
        "      if j > 20:\n",
        "        print(\"\")\n",
        "        j = 0\n",
        "\n",
        "  return keynums_dict, colnames\n",
        "\n",
        "    \n",
        "    \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Called from within search(). Creates sparce matrix of user's search.\n",
        "# If user's search is in the list of keywords, add that keyword to the sparce matrix.\n",
        "# Also adds the WordNet lexical similarity score for very similar keywords to the \n",
        "# user's search to return more relevant results.\n",
        "#\n",
        "# inputs:\n",
        "#    user_search: string containing the lowercased user's search\n",
        "#    keywords_list: list of the keywords correspoding to each number in the sparce vector\n",
        "#         generated by create_tfdif()\n",
        "#    basic: defaults to False, set to True for a search without WordNet, for\n",
        "#         testing purposes\n",
        "# output: returns a sparce matrix of the user's search, matching keywords in the\n",
        "#         search and including the similarity scores for highly similar keywords\n",
        "\n",
        "def get_user_matrix(user_search, keywords_list, basic=False):\n",
        "  new_search = []\n",
        "\n",
        "  # create sparce matrix of the user's search\n",
        "  user_matrix = []\n",
        "\n",
        "  # create sparce matrix of user search based on keywords from course descriptions\n",
        "  # uses wordnet to also match the user's search to synonyms\n",
        "  if not basic:\n",
        "    for word in keywords_list:\n",
        "      running_score = 0\n",
        "      if word in user_search.split(\" \"):\n",
        "        running_score += 1\n",
        "      else:\n",
        "        for term in user_search.split(\" \"):\n",
        "          score = None\n",
        "          if len(wordnet.synsets(term)) > 0:\n",
        "            wn_term = wordnet.synsets(term)[0]\n",
        "            if len(wordnet.synsets(word)) > 0:\n",
        "              wn_word = wordnet.synsets(word)[0]\n",
        "              score = wn_term.wup_similarity(wn_word)\n",
        "          if score is None:\n",
        "            score = 0\n",
        "          if score > 0.9 and score < 1.0:   # cutoff for word similarity\n",
        "            running_score += score    \n",
        "          if score == 1.0:\n",
        "            running_score += 1.0\n",
        "      if running_score >= 0.9:\n",
        "        user_matrix.append(running_score)\n",
        "      else:\n",
        "        user_matrix.append(0)\n",
        "  \n",
        "  # search without WordNet for testing purposes\n",
        "  if basic:\n",
        "    for i in range(len(keywords_list)):\n",
        "      present = False\n",
        "      for word in user_search.split(\" \"):\n",
        "        if word == keywords_list[i]:\n",
        "          present = True\n",
        "      if present:\n",
        "        user_matrix.append(1)\n",
        "      else:\n",
        "        user_matrix.append(0)\n",
        "\n",
        "  # normalize matrix\n",
        "  numsum = max(user_matrix)\n",
        "  if numsum != 0:\n",
        "    for i in range(len(user_matrix)):\n",
        "      user_matrix[i] = user_matrix[i]/numsum\n",
        "\n",
        "  return user_matrix\n",
        "\n",
        "# test case\n",
        "# get_user_matrix(\"cats lion fruit american\", [\"dogs\", \"lion\", \"cat\", \"strawberry\", \"sheep\", \"cats\", \"russian\", \"russia\", \"america\"])"
      ],
      "metadata": {
        "id": "qHL2_8kMrEBs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XLtdV4i8KVgS"
      },
      "outputs": [],
      "source": [
        "# Function that handles the user's search. Prints prompt and creates sparce matrix\n",
        "# of user search. Compares the user's matrix to every course's sparce matrix using\n",
        "# cosine similarity. Prints top ten most relevant courses and their course\n",
        "# descriptions.\n",
        "#\n",
        "# inputs:\n",
        "#    keynums_dict: dictionary of the course names and their sparce vectors\n",
        "#    matrix_names: list of the keywords correspoding to each number in the sparce vector\n",
        "#         generated by create_tfdif()\n",
        "#    basic: defaults to False, set to True for a search without WordNet, for\n",
        "#         testing purposes\n",
        "# outputs: none except text of course description results printed to console\n",
        "\n",
        "def search(keynums_dict, matrix_names, classdesc_dict, basic=False):\n",
        "  user_search = input(\"Please enter your search: \").lower()\n",
        "\n",
        "  if basic:\n",
        "    print(\"Using basic search function.\")\n",
        "  user_matrix = get_user_matrix(user_search, matrix_names, basic)\n",
        "\n",
        "  # get cosine similarity of user search matrix to all matricies of course descriptions\n",
        "  class_list = []\n",
        "  matrix_list = []\n",
        "  for key in keynums_dict: # create matching list of classes and sparce matricies\n",
        "    class_list.append(key)\n",
        "    matrix_list.append(keynums_dict[key])\n",
        "\n",
        "  # get matrices with highest cosine similarity to search matrix\n",
        "  matrix_list.insert(0, user_matrix)\n",
        "  matrix_matrix = np.array(matrix_list)  # convert to matrix for comparison\n",
        "  dist_out = 1-pairwise_distances(matrix_matrix, metric=\"cosine\")\n",
        "  similarity = list(dist_out[0])\n",
        "  sim_index = [i for i,v in enumerate(similarity) if v > 0]   # index of non-zero values\n",
        "  search_list = []\n",
        "  for i in range(len(similarity)):  # create list of non-zero values and the courses they belong to\n",
        "    if i in sim_index:\n",
        "      if i == 0:  # matching own matrix\n",
        "        continue\n",
        "      search_list.append((class_list[i-1], similarity[i]))\n",
        "  \n",
        "  # return course names and descriptions from search\n",
        "  search_list.sort(key=lambda a:a[1], reverse=True)\n",
        "  i = 0\n",
        "  print(\"Search results:\")\n",
        "  for course in search_list:\n",
        "    if i > 9: # if there are more than 10 non-zero courses, return 10 with highest similarity\n",
        "      break\n",
        "    print(str(i+1) + \". \" + course[0])\n",
        "    j = 0\n",
        "    for word in classdesc_dict[course[0]].split(\" \"):\n",
        "      print(word, end = \" \")\n",
        "      if j > 10:\n",
        "        print(\"\")\n",
        "        j = 0\n",
        "      j += 1\n",
        "    print(\"\")\n",
        "    i += 1\n",
        "\n",
        "  if not search_list:\n",
        "    print(\"Sorry, no results found.\")\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Gb0kepsGxxlD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be04492e-c1c7-4d2d-9ec6-529c3c7b6778"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# Full web-scraper\n",
        "# \n",
        "# Scrapes courses and course descriptions from Timetable website, generates\n",
        "# dictionary and \"course_desc.txt\" file necessary for TF-IDF and search.\n",
        "# Note: this will take about 17 minutes because of the structure of the Timetable\n",
        "#\n",
        "# DO NOT RUN BOTH THIS CELL AND THE CELL DIRECTLY BELOW IT - they have duplicate\n",
        "# functionality\n",
        "\n",
        "datatable = get_data()\n",
        "classdesc_dict = make_list_file(datatable)\n",
        "keynums_dict, matrix_names = create_tfidf(classdesc_dict)\n",
        "\n",
        "cell_executed = True  # prevents cell below from being run if user hits \"run all\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Time-saver\n",
        "# \n",
        "# Converts \"course_desc.txt\" file to dictionary necessary for TF-IDF and search.\n",
        "# Saves time because the Timetable website does not have to be scraped.\n",
        "# Note: must upload \"course_dec.txt\" to Files tab on left in Colab\n",
        "#\n",
        "# DO NOT RUN BOTH THIS CELL AND THE CELL DIRECTLY ABOVE IT - they have duplicate\n",
        "# functionality\n",
        "\n",
        "if not cell_executed:\n",
        "  classdesc_dict = get_dict_from_file(\"course_desc.txt\")\n",
        "  keynums_dict, matrix_names = create_tfidf(classdesc_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x7ZLUr5UROa",
        "outputId": "22873629-b1d7-47a7-e048-b300b5b319d3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nibp03psLzml",
        "outputId": "7ead6928-b4af-4535-b4c6-b2eb110854aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your search: calculus\n",
            "Search results:\n",
            "1. Calculus\n",
            "This course is an introduction to single variable calculus aimed at students \n",
            "who have seen some calculus before, either before matriculation or in \n",
            "MATH 1.  MATH 3 begins by revisiting the core topics in \n",
            "MATH 1 - convergence, limits, and derivatives - in greater depth \n",
            "before moving to applications of differentiation such as related rates, finding \n",
            "extreme values, and optimization.  The course then turns to integration theory, \n",
            "introducing the integral via Riemann sums, the fundamental theorem of calculus, \n",
            "and basic techniques of integration.  \n",
            " \n",
            "2. Accelerated Multivar Calc\n",
            "This briskly paced course can be viewed as equivalent to MATH 13 \n",
            "in terms of prerequisites, but is designed especially for first-year students \n",
            "who have successfully completed a BC calculus curriculum in secondary school. \n",
            "In particular, as part of its syllabus it includes most of \n",
            "the multivariable calculus material present in MATH 8 together with the \n",
            "material from MATH 13. Topics include vector geometry, equations of lines \n",
            "and planes, and space curves (velocity, acceleration, arclength), limits and continuity, \n",
            "partial derivatives, tangent planes and differentials, the Chain Rule, directional derivatives \n",
            "and applications, and optimization problems. It continues with multiple integration, vector \n",
            "fields, line integrals, and finishes with a study of Green's and \n",
            "Stokes' theorem.\n",
            " \n",
            "3. Multivar Calc with Lin Alg\n",
            "This course includes the multivariable calculus material present in MATH 8 along \n",
            "with a brief introduction to concepts from linear algebra, a topic \n",
            "pervasive throughout mathematics and its applications.   The introduction to linear algebra \n",
            "enables a more thorough understanding of multivariable calculus.  Topics include vector \n",
            "geometry, equations of lines and planes, matrices and linear transformations, space \n",
            "curves (velocity, acceleration, arclength), functions of several variables (limits and continuity, \n",
            "partial derivatives, the derivative as a linear transformation, tangent planes and \n",
            "linear approximation, the Chain Rule, directional derivatives and applications, and optimization \n",
            "problems including the use of Lagrange multipliers).\n",
            " \n",
            "4. Calculus on Manifolds\n",
            "Manifolds provide mathematicians and other scientists with a way of grappling with \n",
            "the concept of “space” (from a global viewpoint). The space occupied \n",
            "by an object. The space that we inhabit. The space of \n",
            "solutions to a system of equations. Or, perhaps, the space of \n",
            "configurations of a mechanical system. While manifolds are central to the \n",
            "study of geometry and topology, they also provide an appropriate framework \n",
            "in which to explore aspects of mathematical physics, dynamics, control theory, \n",
            "medical imaging, and robotics, to name just a few. This course \n",
            "will demonstrate how ideas from calculus can be generalized to manifolds, \n",
            "providing a new perspective and toolkit with which to explore problems \n",
            "where “space” plays a fundamental role.\n",
            " \n",
            "5. Math Models in Social Sci\n",
            "Disciplines such as anthropology, economics, sociology, psychology, and linguistics all now make \n",
            "extensive use of mathematical models, using the tools of calculus, probability, \n",
            "game theory, network theory, often mixed with a healthy dose of \n",
            "computing. This course introduces students to a range of techniques using \n",
            "current and relevant examples. Students interested in further study of these \n",
            "and related topics are referred to the courses listed in the \n",
            "Mathematics and Social Sciences program.\n",
            " \n",
            "6. Discrete Math Computer Sci\n",
            "This course develops the mathematical foundations of computer science that are not \n",
            "calculus-based. It covers basic set theory, logic, mathematical proof techniques, and \n",
            "a selection of discrete mathematics topics such as  combinatorics (counting),  discrete \n",
            "probability, number theory,and graph theory. The mathematics is frequently motivated using \n",
            "computer science applications.\n",
            " \n"
          ]
        }
      ],
      "source": [
        "# User interface search function. Returns courses from the Dartmouth Timetable\n",
        "# relevant to the user's search.\n",
        "# Note: the first time you run the search, it can take up to a minute. After that, \n",
        "#       the search is fairly quick\n",
        "#\n",
        "# Instructions: Run cell by pressing start button on the left. Type search terms \n",
        "# into the box that appears. If there are relevant courses, they will appear with\n",
        "# the most relevant courses at the top. Run the cell again to make another search.\n",
        "\n",
        "search(keynums_dict, matrix_names, classdesc_dict)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Chloe Fugle - Final Project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}